2019-05-29 14:58:45,512 3d-object-detection INFO: Using 1 GPUs
2019-05-29 14:58:45,512 3d-object-detection INFO: Namespace(cfg='configs/all_nuscene_fhd.yaml', distributed=False, local_rank=0, model_dir='nusc')
2019-05-29 14:58:45,512 3d-object-detection INFO: Collecting env info (might take some time)
2019-05-29 14:58:55,243 3d-object-detection INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.6 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609
CMake version: version 3.13.4

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 1080 Ti
Nvidia driver version: 390.30
cuDNN version: /unsullied/sharefs/_admin/cuda/cuda-9.0/cudnn/v7.4.1/lib64/libcudnn.so.7.4.1

Versions of relevant libraries:
[pip3] numpy==1.14.5
[pip3] numpydoc==0.8.0
[pip3] torch==1.1.0
[pip3] torchvision==0.2.2.post3
[conda] blas                      1.0                         mkl  
[conda] mkl                       2018.0.2                      1  
[conda] mkl-service               1.1.2            py36h17a0993_4  
[conda] mkl_fft                   1.0.1            py36h3010b51_0  
[conda] mkl_random                1.0.1            py36h629b387_0  
[conda] torch                     1.1.0                    pypi_0    pypi
[conda] torchvision               0.2.2.post3              pypi_0    pypi
        Pillow (5.2.0)
2019-05-29 14:58:55,245 3d-object-detection INFO: 
local_rank: 0
input:
    num_point_features: 5
    voxel:
        voxel_size: [0.1, 0.1, 0.2]
        point_cloud_range: [-50.4, -50.4, -5.0, 50.4, 50.4, 3.0]
        max_num_points: 20
        max_num_voxels: 40000
    train:
        batch_size: 5
        num_epochs: 20
        dataset:
            type: "NuScenesDataset"
            root_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data"
            info_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data/infos_train_10sweeps_withvelo.pkl"
            nsweeps: 10
        preprocess:
            shuffle: False
            num_workers: 5
            gt_location_noise: [0, 0, 0]
            gt_rotation_noise: [0, 0]
            global_rotation_noise: [-0.3925, 0.3925]
            global_scale_noise: [0.95, 1.05]
            global_rotation_per_object_range: [0, 0]
            global_translation_noise: [0.2, 0.2, 0.2]
            anchor_area_threshold: -1
            remove_points_after_sample: False
            gt_drop_percentage: 0.0
            gt_drop_max_keep_points: 15
            remove_unknow_examples: False
            remove_environment: False
            db_sampler:
                enable: True
                db_info_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data/dbinfos_train_10sweeps_withvelo.pkl"
                db_preprocess_steps:
                    filter_by_min_num_points:
                        type: "filter_by_min_num_points"
                        classes: ["car","truck", "construction_vehicle", "bus", "trailer", "barrier", "motorcycle", "bicycle", "pedestrian", "traffic_cone"] 
                        values: [5, 5, 5, 5, 5, 5, 5, 5, 5, 5]
                    filter_by_difficulty:
                        type: "filter_by_difficulty"
                        value: [-1,]
                global_random_rotation_range_per_object: [0, 0]
                rate: 1.0
                sample_groups:
                     classes: ["car","truck", "construction_vehicle", "bus", "trailer", "barrier", "motorcycle", "bicycle", "pedestrian", "traffic_cone"] 
                     values: [2, 3, 7, 4, 6, 2, 6, 6, 2, 2]

    eval:
        batch_size: 5
        dataset:
            type: "NuScenesDataset"
            root_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data"
            info_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data/infos_val_10sweeps_withvelo.pkl"
            nsweeps: 10
        preprocess:
            max_num_voxels: 60000
            shuffle: False
            num_workers: 3
            anchor_area_threshold: -1
            remove_environment: False

box_coder:
    type: "ground_box3d_coder"
    value:
        n_dim: 9
        linear_dim: False
        encode_angle_vector: False

target_assigner:
    anchor_generators:
        anchor_types: ["anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range"]
        anchor_dims: [9,9,9,9,9,9,9,9,9,9]
        anchor_sizes: [[1.97, 4.63, 1.74],[2.51, 6.93, 2.84],[2.85, 6.37, 3.19],[2.94, 10.5, 3.47],[2.90, 12.29, 3.87],[2.53, 0.50, 0.98],[0.77, 2.11, 1.47],[0.60, 1.70, 1.28],[0.67, 0.73, 1.77],[0.41, 0.41, 1.07]]
        anchor_ranges: [[-50.4, -50.4, -0.95, 50.4, 50.4, -0.95],[-50.4, -50.4, -0.40, 50.4, 50.4, -0.40],[-50.4, -50.4, -0.225, 50.4, 50.4, -0.225],[-50.4, -50.4, -0.085, 50.4, 50.4, -0.085],[-50.4, -50.4, 0.115, 50.4, 50.4, 0.115],[-50.4, -50.4, -1.33, 50.4, 50.4, -1.33],[-50.4, -50.4, -1.085, 50.4, 50.4, -1.085],[-50.4, -50.4, -1.18, 50.4, 50.4, -1.18],[-50.4, -50.4, -0.935, 50.4, 50.4, -0.935],[-50.4, -50.4, -1.285, 50.4, 50.4, -1.285]]
        anchor_rotations: [[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57]]
        anchor_velocities: [[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0]]
        anchor_matched_thresholds: [0.6,0.55,0.5,0.55,0.5,0.55,0.5,0.5,0.6,0.6]
        anchor_unmatched_thresholds: [0.45,0.4,0.3,0.4,0.35,0.4,0.3,0.35,0.4,0.4]
        anchor_class_names: ["car","truck", "construction_vehicle", "bus", "trailer", "barrier", "motorcycle", "bicycle", "pedestrian", "traffic_cone"]
        sample_positive_fraction: -1
        sample_size: 512
        region_similarity_calculator: 
            type: "nearest_iou_similarity"
            value: 0
model:
    encoder:
        vfe:
            type: "VoxelFeatureExtractorV3" #"PIXORFeatureLayer"
            num_filters: [16,]
            with_distance: False
            num_input_features: 5
        middle:
            type: "SpMiddleFHD"
            num_filters_down1: []
            num_filters_down2: []
            downsample_factor: 8
            num_input_features: 5
    decoder:
        rpn:
            type: "RPNV2"
            layer_nums: [5, 5]
            downsample_layer_strides: [1, 2]
            downsample_num_filters: [128, 256]
            upsample_layer_strides: [1, 2]
            upsample_num_filters: [128, 256]
            group_norm: False
            num_groups: 32
            num_input_features: 128
        head:
            tasks:
                num_classes: [1, 2, 2, 1, 2, 2]
                class_names: [["car"], ["truck", "construction_vehicle"], ["bus", "trailer"], ["barrier"], ["motorcycle", "bicycle"], ["pedestrian", "traffic_cone"]]
            weights: [0.7, 1.2, 1.5, 1.2, 1.5, 0.8]
        auxiliary:
            use_direction_classifier: True
            direction_offset: 0.785
    post_process:
        post_center_limit_range: [-61.2, -61.2, -10.0, 61.2, 61.2, 10.0]
        use_rotate_nms: True
        use_multi_class_nms: False
        nms_pre_max_size: 1000
        nms_post_max_size: 80
        nms_score_threshold: 0.1
        nms_iou_threshold: 0.2

    loss:
        loss_scale_factor: -1
        loss_norm_type: "NormByNumPositives"
        pos_class_weight: 1.0
        neg_class_weight: 2.0
        use_sigmoid_score: True
        encode_background_as_zeros: True
        encode_rad_error_by_sin: True
        classification_loss:
            type: "weighted_sigmoid_focal"
            value: 
                alpha: 0.25
                gamma: 2.0
                anchorwise_output: True
        localization_loss:
            type: "weighted_smooth_l1"
            value: 
                sigma: 3.0
                code_weight: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.2, 1.0]
        classification_loss_weight: 1.0
        localization_loss_weight: 1.0
        direction_loss_weight: 0.2
        rpn_thresholds: [0.1,0.3,0.5,0.7,0.8,0.9]

optimizer:
    type: "adam"
    value: 
        lr:
            type: "one_cycle"
            value: 
                lr_max: 0.04
                moms: [0.95, 0.85]
                div_factor: 10.0
                pct_start: 0.4
        amsgrad: 0.0
        wd: 0.01
    fixed_wd: True
    moving_average: False

2019-05-29 14:58:56,230 Training INFO: Using direction offset 0.785000 to fix aoe
2019-05-29 14:58:56,231 Training INFO: Voxel Feature Encoder: VoxelFeatureExtractorV3
2019-05-29 14:58:56,231 Training INFO: Middle class name: SpMiddleFHD
2019-05-29 14:58:56,247 Training INFO: RPN class name: RPNV2
2019-05-29 14:58:56,296 Training INFO: num_classes: [1, 2, 2, 1, 2, 2]
2019-05-29 14:58:56,296 Training INFO: num_preds: [18, 36, 36, 18, 36, 36]
2019-05-29 14:58:56,296 Training INFO: num_dirs: [4, 8, 8, 4, 8, 8]
2019-05-29 14:58:56,300 Training INFO: Finish RPNBase Initialization
2019-05-29 14:58:56,302 Training INFO: Model Articutures: VoxelNet(
  (_voxel_feature_extractor): VoxelFeatureExtractorV3()
  (_middle_feature_extractor): SpMiddleFHD(
    (middle_conv): SparseSequential(
      (0): DefaultArgLayer()
      (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): DefaultArgLayer()
      (4): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): DefaultArgLayer()
      (7): DefaultArgLayer(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (8): ReLU()
      (9): DefaultArgLayer()
      (10): DefaultArgLayer(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (11): ReLU()
      (12): DefaultArgLayer()
      (13): DefaultArgLayer(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (14): ReLU()
      (15): DefaultArgLayer()
      (16): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (17): ReLU()
      (18): DefaultArgLayer()
      (19): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (20): ReLU()
      (21): DefaultArgLayer()
      (22): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (23): ReLU()
      (24): DefaultArgLayer()
      (25): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (26): ReLU()
      (27): DefaultArgLayer()
      (28): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (29): ReLU()
      (30): DefaultArgLayer()
      (31): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (32): ReLU()
      (33): DefaultArgLayer()
      (34): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (35): ReLU()
      (36): DefaultArgLayer()
      (37): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (38): ReLU()
      (39): DefaultArgLayer()
      (40): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (41): ReLU()
    )
  )
  (_rpn): RPNV2(
    (blocks): ModuleList(
      (0): Sequential(
        (0): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
        (1): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
        (2): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (3): ReLU()
        (4): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (5): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (6): ReLU()
        (7): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (8): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (9): ReLU()
        (10): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (11): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (12): ReLU()
        (13): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (14): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (15): ReLU()
        (16): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (17): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (18): ReLU()
      )
      (1): Sequential(
        (0): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
        (1): DefaultArgLayer(128, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)
        (2): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (3): ReLU()
        (4): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (5): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (6): ReLU()
        (7): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (8): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (9): ReLU()
        (10): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (11): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (12): ReLU()
        (13): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (14): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (15): ReLU()
        (16): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (17): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (18): ReLU()
      )
    )
    (deblocks): ModuleList(
      (0): Sequential(
        (0): DefaultArgLayer(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (1): Sequential(
        (0): DefaultArgLayer(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
        (1): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
    (tasks): ModuleList(
      (0): RPNHead(
        (conv_box): Conv2d(384, 18, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 2, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 4, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): RPNHead(
        (conv_box): Conv2d(384, 36, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
      )
      (2): RPNHead(
        (conv_box): Conv2d(384, 36, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
      )
      (3): RPNHead(
        (conv_box): Conv2d(384, 18, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 2, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 4, kernel_size=(1, 1), stride=(1, 1))
      )
      (4): RPNHead(
        (conv_box): Conv2d(384, 36, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
      )
      (5): RPNHead(
        (conv_box): Conv2d(384, 36, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
  (rpn_acc): Accuracy()
  (rpn_precision): Precision()
  (rpn_recall): Recall()
  (rpn_metrics): PrecisionRecall()
  (rpn_cls_loss): Scalar()
  (rpn_loc_loss): Scalar()
  (rpn_total_loss): Scalar()
)
2019-05-29 14:59:08,076 Training INFO: Training use Single-GPU
2019-05-29 15:00:32,704 3d-object-detection INFO: Using 1 GPUs
2019-05-29 15:00:32,704 3d-object-detection INFO: Namespace(cfg='configs/all_nuscene_fhd.yaml', distributed=False, local_rank=0, model_dir='nusc')
2019-05-29 15:00:32,704 3d-object-detection INFO: Collecting env info (might take some time)
2019-05-29 15:00:40,795 3d-object-detection INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.6 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609
CMake version: version 3.13.4

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 1080 Ti
Nvidia driver version: 390.30
cuDNN version: /unsullied/sharefs/_admin/cuda/cuda-9.0/cudnn/v7.4.1/lib64/libcudnn.so.7.4.1

Versions of relevant libraries:
[pip3] numpy==1.14.5
[pip3] numpydoc==0.8.0
[pip3] torch==1.1.0
[pip3] torchvision==0.2.2.post3
[conda] blas                      1.0                         mkl  
[conda] mkl                       2018.0.2                      1  
[conda] mkl-service               1.1.2            py36h17a0993_4  
[conda] mkl_fft                   1.0.1            py36h3010b51_0  
[conda] mkl_random                1.0.1            py36h629b387_0  
[conda] torch                     1.1.0                    pypi_0    pypi
[conda] torchvision               0.2.2.post3              pypi_0    pypi
        Pillow (5.2.0)
2019-05-29 15:00:40,796 3d-object-detection INFO: 
local_rank: 0
input:
    num_point_features: 5
    voxel:
        voxel_size: [0.1, 0.1, 0.2]
        point_cloud_range: [-50.4, -50.4, -5.0, 50.4, 50.4, 3.0]
        max_num_points: 20
        max_num_voxels: 40000
    train:
        batch_size: 5
        num_epochs: 20
        dataset:
            type: "NuScenesDataset"
            root_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data"
            info_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data/infos_train_10sweeps_withvelo.pkl"
            nsweeps: 10
        preprocess:
            shuffle: False
            num_workers: 5
            gt_location_noise: [0, 0, 0]
            gt_rotation_noise: [0, 0]
            global_rotation_noise: [-0.3925, 0.3925]
            global_scale_noise: [0.95, 1.05]
            global_rotation_per_object_range: [0, 0]
            global_translation_noise: [0.2, 0.2, 0.2]
            anchor_area_threshold: -1
            remove_points_after_sample: False
            gt_drop_percentage: 0.0
            gt_drop_max_keep_points: 15
            remove_unknow_examples: False
            remove_environment: False
            db_sampler:
                enable: True
                db_info_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data/dbinfos_train_10sweeps_withvelo.pkl"
                db_preprocess_steps:
                    filter_by_min_num_points:
                        type: "filter_by_min_num_points"
                        classes: ["car","truck", "construction_vehicle", "bus", "trailer", "barrier", "motorcycle", "bicycle", "pedestrian", "traffic_cone"] 
                        values: [5, 5, 5, 5, 5, 5, 5, 5, 5, 5]
                    filter_by_difficulty:
                        type: "filter_by_difficulty"
                        value: [-1,]
                global_random_rotation_range_per_object: [0, 0]
                rate: 1.0
                sample_groups:
                     classes: ["car","truck", "construction_vehicle", "bus", "trailer", "barrier", "motorcycle", "bicycle", "pedestrian", "traffic_cone"] 
                     values: [2, 3, 7, 4, 6, 2, 6, 6, 2, 2]

    eval:
        batch_size: 5
        dataset:
            type: "NuScenesDataset"
            root_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data"
            info_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data/infos_val_10sweeps_withvelo.pkl"
            nsweeps: 10
        preprocess:
            max_num_voxels: 60000
            shuffle: False
            num_workers: 3
            anchor_area_threshold: -1
            remove_environment: False

box_coder:
    type: "ground_box3d_coder"
    value:
        n_dim: 9
        linear_dim: False
        encode_angle_vector: False

target_assigner:
    anchor_generators:
        anchor_types: ["anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range"]
        anchor_dims: [9,9,9,9,9,9,9,9,9,9]
        anchor_sizes: [[1.97, 4.63, 1.74],[2.51, 6.93, 2.84],[2.85, 6.37, 3.19],[2.94, 10.5, 3.47],[2.90, 12.29, 3.87],[2.53, 0.50, 0.98],[0.77, 2.11, 1.47],[0.60, 1.70, 1.28],[0.67, 0.73, 1.77],[0.41, 0.41, 1.07]]
        anchor_ranges: [[-50.4, -50.4, -0.95, 50.4, 50.4, -0.95],[-50.4, -50.4, -0.40, 50.4, 50.4, -0.40],[-50.4, -50.4, -0.225, 50.4, 50.4, -0.225],[-50.4, -50.4, -0.085, 50.4, 50.4, -0.085],[-50.4, -50.4, 0.115, 50.4, 50.4, 0.115],[-50.4, -50.4, -1.33, 50.4, 50.4, -1.33],[-50.4, -50.4, -1.085, 50.4, 50.4, -1.085],[-50.4, -50.4, -1.18, 50.4, 50.4, -1.18],[-50.4, -50.4, -0.935, 50.4, 50.4, -0.935],[-50.4, -50.4, -1.285, 50.4, 50.4, -1.285]]
        anchor_rotations: [[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57]]
        anchor_velocities: [[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0]]
        anchor_matched_thresholds: [0.6,0.55,0.5,0.55,0.5,0.55,0.5,0.5,0.6,0.6]
        anchor_unmatched_thresholds: [0.45,0.4,0.3,0.4,0.35,0.4,0.3,0.35,0.4,0.4]
        anchor_class_names: ["car","truck", "construction_vehicle", "bus", "trailer", "barrier", "motorcycle", "bicycle", "pedestrian", "traffic_cone"]
        sample_positive_fraction: -1
        sample_size: 512
        region_similarity_calculator: 
            type: "nearest_iou_similarity"
            value: 0
model:
    encoder:
        vfe:
            type: "VoxelFeatureExtractorV3" #"PIXORFeatureLayer"
            num_filters: [16,]
            with_distance: False
            num_input_features: 5
        middle:
            type: "SpMiddleFHD"
            num_filters_down1: []
            num_filters_down2: []
            downsample_factor: 8
            num_input_features: 5
    decoder:
        rpn:
            type: "RPNV2"
            layer_nums: [5, 5]
            downsample_layer_strides: [1, 2]
            downsample_num_filters: [128, 256]
            upsample_layer_strides: [1, 2]
            upsample_num_filters: [128, 256]
            group_norm: False
            num_groups: 32
            num_input_features: 128
        head:
            tasks:
                num_classes: [1, 2, 2, 1, 2, 2]
                class_names: [["car"], ["truck", "construction_vehicle"], ["bus", "trailer"], ["barrier"], ["motorcycle", "bicycle"], ["pedestrian", "traffic_cone"]]
            weights: [0.7, 1.2, 1.5, 1.2, 1.5, 0.8]
        auxiliary:
            use_direction_classifier: True
            direction_offset: 0.785
    post_process:
        post_center_limit_range: [-61.2, -61.2, -10.0, 61.2, 61.2, 10.0]
        use_rotate_nms: True
        use_multi_class_nms: False
        nms_pre_max_size: 1000
        nms_post_max_size: 80
        nms_score_threshold: 0.1
        nms_iou_threshold: 0.2

    loss:
        loss_scale_factor: -1
        loss_norm_type: "NormByNumPositives"
        pos_class_weight: 1.0
        neg_class_weight: 2.0
        use_sigmoid_score: True
        encode_background_as_zeros: True
        encode_rad_error_by_sin: True
        classification_loss:
            type: "weighted_sigmoid_focal"
            value: 
                alpha: 0.25
                gamma: 2.0
                anchorwise_output: True
        localization_loss:
            type: "weighted_smooth_l1"
            value: 
                sigma: 3.0
                code_weight: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.2, 1.0]
        classification_loss_weight: 1.0
        localization_loss_weight: 1.0
        direction_loss_weight: 0.2
        rpn_thresholds: [0.1,0.3,0.5,0.7,0.8,0.9]

optimizer:
    type: "adam"
    value: 
        lr:
            type: "one_cycle"
            value: 
                lr_max: 0.04
                moms: [0.95, 0.85]
                div_factor: 10.0
                pct_start: 0.4
        amsgrad: 0.0
        wd: 0.01
    fixed_wd: True
    moving_average: False

2019-05-29 15:00:41,973 Training INFO: Using direction offset 0.785000 to fix aoe
2019-05-29 15:00:41,973 Training INFO: Voxel Feature Encoder: VoxelFeatureExtractorV3
2019-05-29 15:00:41,974 Training INFO: Middle class name: SpMiddleFHD
2019-05-29 15:00:41,990 Training INFO: RPN class name: RPNV2
2019-05-29 15:00:42,040 Training INFO: num_classes: [1, 2, 2, 1, 2, 2]
2019-05-29 15:00:42,040 Training INFO: num_preds: [18, 36, 36, 18, 36, 36]
2019-05-29 15:00:42,040 Training INFO: num_dirs: [4, 8, 8, 4, 8, 8]
2019-05-29 15:00:42,045 Training INFO: Finish RPNBase Initialization
2019-05-29 15:00:42,046 Training INFO: Model Articutures: VoxelNet(
  (_voxel_feature_extractor): VoxelFeatureExtractorV3()
  (_middle_feature_extractor): SpMiddleFHD(
    (middle_conv): SparseSequential(
      (0): DefaultArgLayer()
      (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): DefaultArgLayer()
      (4): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): DefaultArgLayer()
      (7): DefaultArgLayer(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (8): ReLU()
      (9): DefaultArgLayer()
      (10): DefaultArgLayer(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (11): ReLU()
      (12): DefaultArgLayer()
      (13): DefaultArgLayer(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (14): ReLU()
      (15): DefaultArgLayer()
      (16): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (17): ReLU()
      (18): DefaultArgLayer()
      (19): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (20): ReLU()
      (21): DefaultArgLayer()
      (22): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (23): ReLU()
      (24): DefaultArgLayer()
      (25): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (26): ReLU()
      (27): DefaultArgLayer()
      (28): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (29): ReLU()
      (30): DefaultArgLayer()
      (31): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (32): ReLU()
      (33): DefaultArgLayer()
      (34): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (35): ReLU()
      (36): DefaultArgLayer()
      (37): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (38): ReLU()
      (39): DefaultArgLayer()
      (40): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (41): ReLU()
    )
  )
  (_rpn): RPNV2(
    (blocks): ModuleList(
      (0): Sequential(
        (0): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
        (1): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
        (2): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (3): ReLU()
        (4): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (5): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (6): ReLU()
        (7): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (8): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (9): ReLU()
        (10): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (11): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (12): ReLU()
        (13): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (14): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (15): ReLU()
        (16): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (17): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (18): ReLU()
      )
      (1): Sequential(
        (0): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
        (1): DefaultArgLayer(128, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)
        (2): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (3): ReLU()
        (4): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (5): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (6): ReLU()
        (7): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (8): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (9): ReLU()
        (10): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (11): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (12): ReLU()
        (13): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (14): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (15): ReLU()
        (16): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (17): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (18): ReLU()
      )
    )
    (deblocks): ModuleList(
      (0): Sequential(
        (0): DefaultArgLayer(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (1): Sequential(
        (0): DefaultArgLayer(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
        (1): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
    (tasks): ModuleList(
      (0): RPNHead(
        (conv_box): Conv2d(384, 18, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 2, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 4, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): RPNHead(
        (conv_box): Conv2d(384, 36, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
      )
      (2): RPNHead(
        (conv_box): Conv2d(384, 36, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
      )
      (3): RPNHead(
        (conv_box): Conv2d(384, 18, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 2, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 4, kernel_size=(1, 1), stride=(1, 1))
      )
      (4): RPNHead(
        (conv_box): Conv2d(384, 36, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
      )
      (5): RPNHead(
        (conv_box): Conv2d(384, 36, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
  (rpn_acc): Accuracy()
  (rpn_precision): Precision()
  (rpn_recall): Recall()
  (rpn_metrics): PrecisionRecall()
  (rpn_cls_loss): Scalar()
  (rpn_loc_loss): Scalar()
  (rpn_total_loss): Scalar()
)
2019-05-29 15:00:53,474 Training INFO: Training use Single-GPU
2019-05-29 15:00:53,480 Training INFO: No checkpoint found. Initializing model from scratch
2019-05-29 15:00:53,480 Training INFO: Finish start eval ...
2019-05-29 15:01:56,638 3d-object-detection INFO: Using 1 GPUs
2019-05-29 15:01:56,639 3d-object-detection INFO: Namespace(cfg='configs/all_nuscene_fhd.yaml', distributed=False, local_rank=0, model_dir='nusc')
2019-05-29 15:01:56,639 3d-object-detection INFO: Collecting env info (might take some time)
2019-05-29 15:02:02,843 3d-object-detection INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.6 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609
CMake version: version 3.13.4

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 1080 Ti
Nvidia driver version: 390.30
cuDNN version: /unsullied/sharefs/_admin/cuda/cuda-9.0/cudnn/v7.4.1/lib64/libcudnn.so.7.4.1

Versions of relevant libraries:
[pip3] numpy==1.14.5
[pip3] numpydoc==0.8.0
[pip3] torch==1.1.0
[pip3] torchvision==0.2.2.post3
[conda] blas                      1.0                         mkl  
[conda] mkl                       2018.0.2                      1  
[conda] mkl-service               1.1.2            py36h17a0993_4  
[conda] mkl_fft                   1.0.1            py36h3010b51_0  
[conda] mkl_random                1.0.1            py36h629b387_0  
[conda] torch                     1.1.0                    pypi_0    pypi
[conda] torchvision               0.2.2.post3              pypi_0    pypi
        Pillow (5.2.0)
2019-05-29 15:02:02,844 3d-object-detection INFO: 
local_rank: 0
input:
    num_point_features: 5
    voxel:
        voxel_size: [0.1, 0.1, 0.2]
        point_cloud_range: [-50.4, -50.4, -5.0, 50.4, 50.4, 3.0]
        max_num_points: 20
        max_num_voxels: 40000
    train:
        batch_size: 5
        num_epochs: 20
        dataset:
            type: "NuScenesDataset"
            root_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data"
            info_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data/infos_train_10sweeps_withvelo.pkl"
            nsweeps: 10
        preprocess:
            shuffle: False
            num_workers: 5
            gt_location_noise: [0, 0, 0]
            gt_rotation_noise: [0, 0]
            global_rotation_noise: [-0.3925, 0.3925]
            global_scale_noise: [0.95, 1.05]
            global_rotation_per_object_range: [0, 0]
            global_translation_noise: [0.2, 0.2, 0.2]
            anchor_area_threshold: -1
            remove_points_after_sample: False
            gt_drop_percentage: 0.0
            gt_drop_max_keep_points: 15
            remove_unknow_examples: False
            remove_environment: False
            db_sampler:
                enable: True
                db_info_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data/dbinfos_train_10sweeps_withvelo.pkl"
                db_preprocess_steps:
                    filter_by_min_num_points:
                        type: "filter_by_min_num_points"
                        classes: ["car","truck", "construction_vehicle", "bus", "trailer", "barrier", "motorcycle", "bicycle", "pedestrian", "traffic_cone"] 
                        values: [5, 5, 5, 5, 5, 5, 5, 5, 5, 5]
                    filter_by_difficulty:
                        type: "filter_by_difficulty"
                        value: [-1,]
                global_random_rotation_range_per_object: [0, 0]
                rate: 1.0
                sample_groups:
                     classes: ["car","truck", "construction_vehicle", "bus", "trailer", "barrier", "motorcycle", "bicycle", "pedestrian", "traffic_cone"] 
                     values: [2, 3, 7, 4, 6, 2, 6, 6, 2, 2]

    eval:
        batch_size: 5
        dataset:
            type: "NuScenesDataset"
            root_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data"
            info_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data/infos_val_10sweeps_withvelo.pkl"
            nsweeps: 10
        preprocess:
            max_num_voxels: 60000
            shuffle: False
            num_workers: 3
            anchor_area_threshold: -1
            remove_environment: False

box_coder:
    type: "ground_box3d_coder"
    value:
        n_dim: 9
        linear_dim: False
        encode_angle_vector: False

target_assigner:
    anchor_generators:
        anchor_types: ["anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range"]
        anchor_dims: [9,9,9,9,9,9,9,9,9,9]
        anchor_sizes: [[1.97, 4.63, 1.74],[2.51, 6.93, 2.84],[2.85, 6.37, 3.19],[2.94, 10.5, 3.47],[2.90, 12.29, 3.87],[2.53, 0.50, 0.98],[0.77, 2.11, 1.47],[0.60, 1.70, 1.28],[0.67, 0.73, 1.77],[0.41, 0.41, 1.07]]
        anchor_ranges: [[-50.4, -50.4, -0.95, 50.4, 50.4, -0.95],[-50.4, -50.4, -0.40, 50.4, 50.4, -0.40],[-50.4, -50.4, -0.225, 50.4, 50.4, -0.225],[-50.4, -50.4, -0.085, 50.4, 50.4, -0.085],[-50.4, -50.4, 0.115, 50.4, 50.4, 0.115],[-50.4, -50.4, -1.33, 50.4, 50.4, -1.33],[-50.4, -50.4, -1.085, 50.4, 50.4, -1.085],[-50.4, -50.4, -1.18, 50.4, 50.4, -1.18],[-50.4, -50.4, -0.935, 50.4, 50.4, -0.935],[-50.4, -50.4, -1.285, 50.4, 50.4, -1.285]]
        anchor_rotations: [[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57]]
        anchor_velocities: [[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0]]
        anchor_matched_thresholds: [0.6,0.55,0.5,0.55,0.5,0.55,0.5,0.5,0.6,0.6]
        anchor_unmatched_thresholds: [0.45,0.4,0.3,0.4,0.35,0.4,0.3,0.35,0.4,0.4]
        anchor_class_names: ["car","truck", "construction_vehicle", "bus", "trailer", "barrier", "motorcycle", "bicycle", "pedestrian", "traffic_cone"]
        sample_positive_fraction: -1
        sample_size: 512
        region_similarity_calculator: 
            type: "nearest_iou_similarity"
            value: 0
model:
    encoder:
        vfe:
            type: "VoxelFeatureExtractorV3" #"PIXORFeatureLayer"
            num_filters: [16,]
            with_distance: False
            num_input_features: 5
        middle:
            type: "SpMiddleFHD"
            num_filters_down1: []
            num_filters_down2: []
            downsample_factor: 8
            num_input_features: 5
    decoder:
        rpn:
            type: "RPNV2"
            layer_nums: [5, 5]
            downsample_layer_strides: [1, 2]
            downsample_num_filters: [128, 256]
            upsample_layer_strides: [1, 2]
            upsample_num_filters: [128, 256]
            group_norm: False
            num_groups: 32
            num_input_features: 128
        head:
            tasks:
                num_classes: [1, 2, 2, 1, 2, 2]
                class_names: [["car"], ["truck", "construction_vehicle"], ["bus", "trailer"], ["barrier"], ["motorcycle", "bicycle"], ["pedestrian", "traffic_cone"]]
            weights: [0.7, 1.2, 1.5, 1.2, 1.5, 0.8]
        auxiliary:
            use_direction_classifier: True
            direction_offset: 0.785
    post_process:
        post_center_limit_range: [-61.2, -61.2, -10.0, 61.2, 61.2, 10.0]
        use_rotate_nms: True
        use_multi_class_nms: False
        nms_pre_max_size: 1000
        nms_post_max_size: 80
        nms_score_threshold: 0.1
        nms_iou_threshold: 0.2

    loss:
        loss_scale_factor: -1
        loss_norm_type: "NormByNumPositives"
        pos_class_weight: 1.0
        neg_class_weight: 2.0
        use_sigmoid_score: True
        encode_background_as_zeros: True
        encode_rad_error_by_sin: True
        classification_loss:
            type: "weighted_sigmoid_focal"
            value: 
                alpha: 0.25
                gamma: 2.0
                anchorwise_output: True
        localization_loss:
            type: "weighted_smooth_l1"
            value: 
                sigma: 3.0
                code_weight: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.2, 1.0]
        classification_loss_weight: 1.0
        localization_loss_weight: 1.0
        direction_loss_weight: 0.2
        rpn_thresholds: [0.1,0.3,0.5,0.7,0.8,0.9]

optimizer:
    type: "adam"
    value: 
        lr:
            type: "one_cycle"
            value: 
                lr_max: 0.04
                moms: [0.95, 0.85]
                div_factor: 10.0
                pct_start: 0.4
        amsgrad: 0.0
        wd: 0.01
    fixed_wd: True
    moving_average: False

2019-05-29 15:02:03,644 Training INFO: Using direction offset 0.785000 to fix aoe
2019-05-29 15:02:03,645 Training INFO: Voxel Feature Encoder: VoxelFeatureExtractorV3
2019-05-29 15:02:03,645 Training INFO: Middle class name: SpMiddleFHD
2019-05-29 15:02:03,660 Training INFO: RPN class name: RPNV2
2019-05-29 15:02:03,704 Training INFO: num_classes: [1, 2, 2, 1, 2, 2]
2019-05-29 15:02:03,705 Training INFO: num_preds: [18, 36, 36, 18, 36, 36]
2019-05-29 15:02:03,705 Training INFO: num_dirs: [4, 8, 8, 4, 8, 8]
2019-05-29 15:02:03,709 Training INFO: Finish RPNBase Initialization
2019-05-29 15:02:03,710 Training INFO: Model Articutures: VoxelNet(
  (_voxel_feature_extractor): VoxelFeatureExtractorV3()
  (_middle_feature_extractor): SpMiddleFHD(
    (middle_conv): SparseSequential(
      (0): DefaultArgLayer()
      (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): DefaultArgLayer()
      (4): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): DefaultArgLayer()
      (7): DefaultArgLayer(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (8): ReLU()
      (9): DefaultArgLayer()
      (10): DefaultArgLayer(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (11): ReLU()
      (12): DefaultArgLayer()
      (13): DefaultArgLayer(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (14): ReLU()
      (15): DefaultArgLayer()
      (16): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (17): ReLU()
      (18): DefaultArgLayer()
      (19): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (20): ReLU()
      (21): DefaultArgLayer()
      (22): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (23): ReLU()
      (24): DefaultArgLayer()
      (25): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (26): ReLU()
      (27): DefaultArgLayer()
      (28): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (29): ReLU()
      (30): DefaultArgLayer()
      (31): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (32): ReLU()
      (33): DefaultArgLayer()
      (34): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (35): ReLU()
      (36): DefaultArgLayer()
      (37): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (38): ReLU()
      (39): DefaultArgLayer()
      (40): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (41): ReLU()
    )
  )
  (_rpn): RPNV2(
    (blocks): ModuleList(
      (0): Sequential(
        (0): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
        (1): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
        (2): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (3): ReLU()
        (4): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (5): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (6): ReLU()
        (7): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (8): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (9): ReLU()
        (10): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (11): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (12): ReLU()
        (13): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (14): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (15): ReLU()
        (16): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (17): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (18): ReLU()
      )
      (1): Sequential(
        (0): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
        (1): DefaultArgLayer(128, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)
        (2): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (3): ReLU()
        (4): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (5): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (6): ReLU()
        (7): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (8): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (9): ReLU()
        (10): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (11): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (12): ReLU()
        (13): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (14): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (15): ReLU()
        (16): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (17): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (18): ReLU()
      )
    )
    (deblocks): ModuleList(
      (0): Sequential(
        (0): DefaultArgLayer(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (1): Sequential(
        (0): DefaultArgLayer(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
        (1): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
    (tasks): ModuleList(
      (0): RPNHead(
        (conv_box): Conv2d(384, 18, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 2, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 4, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): RPNHead(
        (conv_box): Conv2d(384, 36, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
      )
      (2): RPNHead(
        (conv_box): Conv2d(384, 36, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
      )
      (3): RPNHead(
        (conv_box): Conv2d(384, 18, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 2, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 4, kernel_size=(1, 1), stride=(1, 1))
      )
      (4): RPNHead(
        (conv_box): Conv2d(384, 36, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
      )
      (5): RPNHead(
        (conv_box): Conv2d(384, 36, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
  (rpn_acc): Accuracy()
  (rpn_precision): Precision()
  (rpn_recall): Recall()
  (rpn_metrics): PrecisionRecall()
  (rpn_cls_loss): Scalar()
  (rpn_loc_loss): Scalar()
  (rpn_total_loss): Scalar()
)
2019-05-29 15:02:15,534 Training INFO: Training use Single-GPU
2019-05-29 15:02:15,538 Training INFO: No checkpoint found. Initializing model from scratch
2019-05-29 15:02:15,538 Training INFO: Finish start eval ...
2019-05-29 15:02:15,539 Training INFO: Start evaluation on dataset for 6019 samples.
2019-05-29 15:04:31,635 3d-object-detection INFO: Using 1 GPUs
2019-05-29 15:04:31,636 3d-object-detection INFO: Namespace(cfg='configs/all_nuscene_fhd.yaml', distributed=False, local_rank=0, model_dir='nusc')
2019-05-29 15:04:31,636 3d-object-detection INFO: Collecting env info (might take some time)
2019-05-29 15:04:37,054 3d-object-detection INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.6 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609
CMake version: version 3.13.4

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 1080 Ti
Nvidia driver version: 390.30
cuDNN version: /unsullied/sharefs/_admin/cuda/cuda-9.0/cudnn/v7.4.1/lib64/libcudnn.so.7.4.1

Versions of relevant libraries:
[pip3] numpy==1.14.5
[pip3] numpydoc==0.8.0
[pip3] torch==1.1.0
[pip3] torchvision==0.2.2.post3
[conda] blas                      1.0                         mkl  
[conda] mkl                       2018.0.2                      1  
[conda] mkl-service               1.1.2            py36h17a0993_4  
[conda] mkl_fft                   1.0.1            py36h3010b51_0  
[conda] mkl_random                1.0.1            py36h629b387_0  
[conda] torch                     1.1.0                    pypi_0    pypi
[conda] torchvision               0.2.2.post3              pypi_0    pypi
        Pillow (5.2.0)
2019-05-29 15:04:37,056 3d-object-detection INFO: 
local_rank: 0
input:
    num_point_features: 5
    voxel:
        voxel_size: [0.1, 0.1, 0.2]
        point_cloud_range: [-50.4, -50.4, -5.0, 50.4, 50.4, 3.0]
        max_num_points: 20
        max_num_voxels: 40000
    train:
        batch_size: 5
        num_epochs: 20
        dataset:
            type: "NuScenesDataset"
            root_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data"
            info_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data/infos_train_10sweeps_withvelo.pkl"
            nsweeps: 10
        preprocess:
            shuffle: False
            num_workers: 5
            gt_location_noise: [0, 0, 0]
            gt_rotation_noise: [0, 0]
            global_rotation_noise: [-0.3925, 0.3925]
            global_scale_noise: [0.95, 1.05]
            global_rotation_per_object_range: [0, 0]
            global_translation_noise: [0.2, 0.2, 0.2]
            anchor_area_threshold: -1
            remove_points_after_sample: False
            gt_drop_percentage: 0.0
            gt_drop_max_keep_points: 15
            remove_unknow_examples: False
            remove_environment: False
            db_sampler:
                enable: True
                db_info_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data/dbinfos_train_10sweeps_withvelo.pkl"
                db_preprocess_steps:
                    filter_by_min_num_points:
                        type: "filter_by_min_num_points"
                        classes: ["car","truck", "construction_vehicle", "bus", "trailer", "barrier", "motorcycle", "bicycle", "pedestrian", "traffic_cone"] 
                        values: [5, 5, 5, 5, 5, 5, 5, 5, 5, 5]
                    filter_by_difficulty:
                        type: "filter_by_difficulty"
                        value: [-1,]
                global_random_rotation_range_per_object: [0, 0]
                rate: 1.0
                sample_groups:
                     classes: ["car","truck", "construction_vehicle", "bus", "trailer", "barrier", "motorcycle", "bicycle", "pedestrian", "traffic_cone"] 
                     values: [2, 3, 7, 4, 6, 2, 6, 6, 2, 2]

    eval:
        batch_size: 5
        dataset:
            type: "NuScenesDataset"
            root_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data"
            info_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data/infos_val_10sweeps_withvelo.pkl"
            nsweeps: 10
        preprocess:
            max_num_voxels: 60000
            shuffle: False
            num_workers: 3
            anchor_area_threshold: -1
            remove_environment: False

box_coder:
    type: "ground_box3d_coder"
    value:
        n_dim: 9
        linear_dim: False
        encode_angle_vector: False

target_assigner:
    anchor_generators:
        anchor_types: ["anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range"]
        anchor_dims: [9,9,9,9,9,9,9,9,9,9]
        anchor_sizes: [[1.97, 4.63, 1.74],[2.51, 6.93, 2.84],[2.85, 6.37, 3.19],[2.94, 10.5, 3.47],[2.90, 12.29, 3.87],[2.53, 0.50, 0.98],[0.77, 2.11, 1.47],[0.60, 1.70, 1.28],[0.67, 0.73, 1.77],[0.41, 0.41, 1.07]]
        anchor_ranges: [[-50.4, -50.4, -0.95, 50.4, 50.4, -0.95],[-50.4, -50.4, -0.40, 50.4, 50.4, -0.40],[-50.4, -50.4, -0.225, 50.4, 50.4, -0.225],[-50.4, -50.4, -0.085, 50.4, 50.4, -0.085],[-50.4, -50.4, 0.115, 50.4, 50.4, 0.115],[-50.4, -50.4, -1.33, 50.4, 50.4, -1.33],[-50.4, -50.4, -1.085, 50.4, 50.4, -1.085],[-50.4, -50.4, -1.18, 50.4, 50.4, -1.18],[-50.4, -50.4, -0.935, 50.4, 50.4, -0.935],[-50.4, -50.4, -1.285, 50.4, 50.4, -1.285]]
        anchor_rotations: [[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57]]
        anchor_velocities: [[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0]]
        anchor_matched_thresholds: [0.6,0.55,0.5,0.55,0.5,0.55,0.5,0.5,0.6,0.6]
        anchor_unmatched_thresholds: [0.45,0.4,0.3,0.4,0.35,0.4,0.3,0.35,0.4,0.4]
        anchor_class_names: ["car","truck", "construction_vehicle", "bus", "trailer", "barrier", "motorcycle", "bicycle", "pedestrian", "traffic_cone"]
        sample_positive_fraction: -1
        sample_size: 512
        region_similarity_calculator: 
            type: "nearest_iou_similarity"
            value: 0
model:
    encoder:
        vfe:
            type: "VoxelFeatureExtractorV3" #"PIXORFeatureLayer"
            num_filters: [16,]
            with_distance: False
            num_input_features: 5
        middle:
            type: "SpMiddleFHD"
            num_filters_down1: []
            num_filters_down2: []
            downsample_factor: 8
            num_input_features: 5
    decoder:
        rpn:
            type: "RPNV2"
            layer_nums: [5, 5]
            downsample_layer_strides: [1, 2]
            downsample_num_filters: [128, 256]
            upsample_layer_strides: [1, 2]
            upsample_num_filters: [128, 256]
            group_norm: False
            num_groups: 32
            num_input_features: 128
        head:
            tasks:
                num_classes: [1, 2, 2, 1, 2, 2]
                class_names: [["car"], ["truck", "construction_vehicle"], ["bus", "trailer"], ["barrier"], ["motorcycle", "bicycle"], ["pedestrian", "traffic_cone"]]
            weights: [0.7, 1.2, 1.5, 1.2, 1.5, 0.8]
        auxiliary:
            use_direction_classifier: True
            direction_offset: 0.785
    post_process:
        post_center_limit_range: [-61.2, -61.2, -10.0, 61.2, 61.2, 10.0]
        use_rotate_nms: True
        use_multi_class_nms: False
        nms_pre_max_size: 1000
        nms_post_max_size: 80
        nms_score_threshold: 0.1
        nms_iou_threshold: 0.2

    loss:
        loss_scale_factor: -1
        loss_norm_type: "NormByNumPositives"
        pos_class_weight: 1.0
        neg_class_weight: 2.0
        use_sigmoid_score: True
        encode_background_as_zeros: True
        encode_rad_error_by_sin: True
        classification_loss:
            type: "weighted_sigmoid_focal"
            value: 
                alpha: 0.25
                gamma: 2.0
                anchorwise_output: True
        localization_loss:
            type: "weighted_smooth_l1"
            value: 
                sigma: 3.0
                code_weight: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.2, 1.0]
        classification_loss_weight: 1.0
        localization_loss_weight: 1.0
        direction_loss_weight: 0.2
        rpn_thresholds: [0.1,0.3,0.5,0.7,0.8,0.9]

optimizer:
    type: "adam"
    value: 
        lr:
            type: "one_cycle"
            value: 
                lr_max: 0.04
                moms: [0.95, 0.85]
                div_factor: 10.0
                pct_start: 0.4
        amsgrad: 0.0
        wd: 0.01
    fixed_wd: True
    moving_average: False

2019-05-29 15:04:37,807 Training INFO: Using direction offset 0.785000 to fix aoe
2019-05-29 15:04:37,807 Training INFO: Voxel Feature Encoder: VoxelFeatureExtractorV3
2019-05-29 15:04:37,807 Training INFO: Middle class name: SpMiddleFHD
2019-05-29 15:04:37,823 Training INFO: RPN class name: RPNV2
2019-05-29 15:04:37,867 Training INFO: num_classes: [1, 2, 2, 1, 2, 2]
2019-05-29 15:04:37,867 Training INFO: num_preds: [18, 36, 36, 18, 36, 36]
2019-05-29 15:04:37,867 Training INFO: num_dirs: [4, 8, 8, 4, 8, 8]
2019-05-29 15:04:37,871 Training INFO: Finish RPNBase Initialization
2019-05-29 15:04:37,872 Training INFO: Model Articutures: VoxelNet(
  (_voxel_feature_extractor): VoxelFeatureExtractorV3()
  (_middle_feature_extractor): SpMiddleFHD(
    (middle_conv): SparseSequential(
      (0): DefaultArgLayer()
      (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): DefaultArgLayer()
      (4): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): DefaultArgLayer()
      (7): DefaultArgLayer(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (8): ReLU()
      (9): DefaultArgLayer()
      (10): DefaultArgLayer(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (11): ReLU()
      (12): DefaultArgLayer()
      (13): DefaultArgLayer(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (14): ReLU()
      (15): DefaultArgLayer()
      (16): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (17): ReLU()
      (18): DefaultArgLayer()
      (19): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (20): ReLU()
      (21): DefaultArgLayer()
      (22): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (23): ReLU()
      (24): DefaultArgLayer()
      (25): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (26): ReLU()
      (27): DefaultArgLayer()
      (28): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (29): ReLU()
      (30): DefaultArgLayer()
      (31): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (32): ReLU()
      (33): DefaultArgLayer()
      (34): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (35): ReLU()
      (36): DefaultArgLayer()
      (37): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (38): ReLU()
      (39): DefaultArgLayer()
      (40): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (41): ReLU()
    )
  )
  (_rpn): RPNV2(
    (blocks): ModuleList(
      (0): Sequential(
        (0): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
        (1): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
        (2): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (3): ReLU()
        (4): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (5): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (6): ReLU()
        (7): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (8): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (9): ReLU()
        (10): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (11): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (12): ReLU()
        (13): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (14): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (15): ReLU()
        (16): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (17): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (18): ReLU()
      )
      (1): Sequential(
        (0): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
        (1): DefaultArgLayer(128, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)
        (2): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (3): ReLU()
        (4): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (5): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (6): ReLU()
        (7): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (8): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (9): ReLU()
        (10): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (11): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (12): ReLU()
        (13): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (14): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (15): ReLU()
        (16): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (17): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (18): ReLU()
      )
    )
    (deblocks): ModuleList(
      (0): Sequential(
        (0): DefaultArgLayer(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (1): Sequential(
        (0): DefaultArgLayer(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
        (1): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
    (tasks): ModuleList(
      (0): RPNHead(
        (conv_box): Conv2d(384, 18, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 2, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 4, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): RPNHead(
        (conv_box): Conv2d(384, 36, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
      )
      (2): RPNHead(
        (conv_box): Conv2d(384, 36, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
      )
      (3): RPNHead(
        (conv_box): Conv2d(384, 18, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 2, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 4, kernel_size=(1, 1), stride=(1, 1))
      )
      (4): RPNHead(
        (conv_box): Conv2d(384, 36, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
      )
      (5): RPNHead(
        (conv_box): Conv2d(384, 36, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
  (rpn_acc): Accuracy()
  (rpn_precision): Precision()
  (rpn_recall): Recall()
  (rpn_metrics): PrecisionRecall()
  (rpn_cls_loss): Scalar()
  (rpn_loc_loss): Scalar()
  (rpn_total_loss): Scalar()
)
2019-05-29 15:04:47,671 Training INFO: Training use Single-GPU
2019-05-29 15:04:47,675 Training INFO: No checkpoint found. Initializing model from scratch
2019-05-29 15:04:47,676 Training INFO: Finish start eval ...
2019-05-29 15:04:47,676 Training INFO: Start evaluation on dataset for 6019 samples.
2019-05-29 15:05:46,886 3d-object-detection INFO: Using 1 GPUs
2019-05-29 15:05:46,886 3d-object-detection INFO: Namespace(cfg='configs/all_nuscene_fhd.yaml', distributed=False, local_rank=0, model_dir='nusc')
2019-05-29 15:05:46,886 3d-object-detection INFO: Collecting env info (might take some time)
2019-05-29 15:05:52,303 3d-object-detection INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.6 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609
CMake version: version 3.13.4

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 1080 Ti
Nvidia driver version: 390.30
cuDNN version: /unsullied/sharefs/_admin/cuda/cuda-9.0/cudnn/v7.4.1/lib64/libcudnn.so.7.4.1

Versions of relevant libraries:
[pip3] numpy==1.14.5
[pip3] numpydoc==0.8.0
[pip3] torch==1.1.0
[pip3] torchvision==0.2.2.post3
[conda] blas                      1.0                         mkl  
[conda] mkl                       2018.0.2                      1  
[conda] mkl-service               1.1.2            py36h17a0993_4  
[conda] mkl_fft                   1.0.1            py36h3010b51_0  
[conda] mkl_random                1.0.1            py36h629b387_0  
[conda] torch                     1.1.0                    pypi_0    pypi
[conda] torchvision               0.2.2.post3              pypi_0    pypi
        Pillow (5.2.0)
2019-05-29 15:05:52,303 3d-object-detection INFO: 
local_rank: 0
input:
    num_point_features: 5
    voxel:
        voxel_size: [0.1, 0.1, 0.2]
        point_cloud_range: [-50.4, -50.4, -5.0, 50.4, 50.4, 3.0]
        max_num_points: 20
        max_num_voxels: 40000
    train:
        batch_size: 5
        num_epochs: 20
        dataset:
            type: "NuScenesDataset"
            root_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data"
            info_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data/infos_train_10sweeps_withvelo.pkl"
            nsweeps: 10
        preprocess:
            shuffle: False
            num_workers: 5
            gt_location_noise: [0, 0, 0]
            gt_rotation_noise: [0, 0]
            global_rotation_noise: [-0.3925, 0.3925]
            global_scale_noise: [0.95, 1.05]
            global_rotation_per_object_range: [0, 0]
            global_translation_noise: [0.2, 0.2, 0.2]
            anchor_area_threshold: -1
            remove_points_after_sample: False
            gt_drop_percentage: 0.0
            gt_drop_max_keep_points: 15
            remove_unknow_examples: False
            remove_environment: False
            db_sampler:
                enable: True
                db_info_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data/dbinfos_train_10sweeps_withvelo.pkl"
                db_preprocess_steps:
                    filter_by_min_num_points:
                        type: "filter_by_min_num_points"
                        classes: ["car","truck", "construction_vehicle", "bus", "trailer", "barrier", "motorcycle", "bicycle", "pedestrian", "traffic_cone"] 
                        values: [5, 5, 5, 5, 5, 5, 5, 5, 5, 5]
                    filter_by_difficulty:
                        type: "filter_by_difficulty"
                        value: [-1,]
                global_random_rotation_range_per_object: [0, 0]
                rate: 1.0
                sample_groups:
                     classes: ["car","truck", "construction_vehicle", "bus", "trailer", "barrier", "motorcycle", "bicycle", "pedestrian", "traffic_cone"] 
                     values: [2, 3, 7, 4, 6, 2, 6, 6, 2, 2]

    eval:
        batch_size: 5
        dataset:
            type: "NuScenesDataset"
            root_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data"
            info_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data/infos_val_10sweeps_withvelo.pkl"
            nsweeps: 10
        preprocess:
            max_num_voxels: 60000
            shuffle: False
            num_workers: 3
            anchor_area_threshold: -1
            remove_environment: False

box_coder:
    type: "ground_box3d_coder"
    value:
        n_dim: 9
        linear_dim: False
        encode_angle_vector: False

target_assigner:
    anchor_generators:
        anchor_types: ["anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range"]
        anchor_dims: [9,9,9,9,9,9,9,9,9,9]
        anchor_sizes: [[1.97, 4.63, 1.74],[2.51, 6.93, 2.84],[2.85, 6.37, 3.19],[2.94, 10.5, 3.47],[2.90, 12.29, 3.87],[2.53, 0.50, 0.98],[0.77, 2.11, 1.47],[0.60, 1.70, 1.28],[0.67, 0.73, 1.77],[0.41, 0.41, 1.07]]
        anchor_ranges: [[-50.4, -50.4, -0.95, 50.4, 50.4, -0.95],[-50.4, -50.4, -0.40, 50.4, 50.4, -0.40],[-50.4, -50.4, -0.225, 50.4, 50.4, -0.225],[-50.4, -50.4, -0.085, 50.4, 50.4, -0.085],[-50.4, -50.4, 0.115, 50.4, 50.4, 0.115],[-50.4, -50.4, -1.33, 50.4, 50.4, -1.33],[-50.4, -50.4, -1.085, 50.4, 50.4, -1.085],[-50.4, -50.4, -1.18, 50.4, 50.4, -1.18],[-50.4, -50.4, -0.935, 50.4, 50.4, -0.935],[-50.4, -50.4, -1.285, 50.4, 50.4, -1.285]]
        anchor_rotations: [[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57]]
        anchor_velocities: [[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0]]
        anchor_matched_thresholds: [0.6,0.55,0.5,0.55,0.5,0.55,0.5,0.5,0.6,0.6]
        anchor_unmatched_thresholds: [0.45,0.4,0.3,0.4,0.35,0.4,0.3,0.35,0.4,0.4]
        anchor_class_names: ["car","truck", "construction_vehicle", "bus", "trailer", "barrier", "motorcycle", "bicycle", "pedestrian", "traffic_cone"]
        sample_positive_fraction: -1
        sample_size: 512
        region_similarity_calculator: 
            type: "nearest_iou_similarity"
            value: 0
model:
    encoder:
        vfe:
            type: "VoxelFeatureExtractorV3" #"PIXORFeatureLayer"
            num_filters: [16,]
            with_distance: False
            num_input_features: 5
        middle:
            type: "SpMiddleFHD"
            num_filters_down1: []
            num_filters_down2: []
            downsample_factor: 8
            num_input_features: 5
    decoder:
        rpn:
            type: "RPNV2"
            layer_nums: [5, 5]
            downsample_layer_strides: [1, 2]
            downsample_num_filters: [128, 256]
            upsample_layer_strides: [1, 2]
            upsample_num_filters: [128, 256]
            group_norm: False
            num_groups: 32
            num_input_features: 128
        head:
            tasks:
                num_classes: [1, 2, 2, 1, 2, 2]
                class_names: [["car"], ["truck", "construction_vehicle"], ["bus", "trailer"], ["barrier"], ["motorcycle", "bicycle"], ["pedestrian", "traffic_cone"]]
            weights: [0.7, 1.2, 1.5, 1.2, 1.5, 0.8]
        auxiliary:
            use_direction_classifier: True
            direction_offset: 0.785
    post_process:
        post_center_limit_range: [-61.2, -61.2, -10.0, 61.2, 61.2, 10.0]
        use_rotate_nms: True
        use_multi_class_nms: False
        nms_pre_max_size: 1000
        nms_post_max_size: 80
        nms_score_threshold: 0.1
        nms_iou_threshold: 0.2

    loss:
        loss_scale_factor: -1
        loss_norm_type: "NormByNumPositives"
        pos_class_weight: 1.0
        neg_class_weight: 2.0
        use_sigmoid_score: True
        encode_background_as_zeros: True
        encode_rad_error_by_sin: True
        classification_loss:
            type: "weighted_sigmoid_focal"
            value: 
                alpha: 0.25
                gamma: 2.0
                anchorwise_output: True
        localization_loss:
            type: "weighted_smooth_l1"
            value: 
                sigma: 3.0
                code_weight: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.2, 1.0]
        classification_loss_weight: 1.0
        localization_loss_weight: 1.0
        direction_loss_weight: 0.2
        rpn_thresholds: [0.1,0.3,0.5,0.7,0.8,0.9]

optimizer:
    type: "adam"
    value: 
        lr:
            type: "one_cycle"
            value: 
                lr_max: 0.04
                moms: [0.95, 0.85]
                div_factor: 10.0
                pct_start: 0.4
        amsgrad: 0.0
        wd: 0.01
    fixed_wd: True
    moving_average: False

2019-05-29 15:05:52,995 Training INFO: Using direction offset 0.785000 to fix aoe
2019-05-29 15:05:52,996 Training INFO: Voxel Feature Encoder: VoxelFeatureExtractorV3
2019-05-29 15:05:52,996 Training INFO: Middle class name: SpMiddleFHD
2019-05-29 15:05:53,011 Training INFO: RPN class name: RPNV2
2019-05-29 15:05:53,056 Training INFO: num_classes: [1, 2, 2, 1, 2, 2]
2019-05-29 15:05:53,056 Training INFO: num_preds: [18, 36, 36, 18, 36, 36]
2019-05-29 15:05:53,056 Training INFO: num_dirs: [4, 8, 8, 4, 8, 8]
2019-05-29 15:05:53,062 Training INFO: Finish RPNBase Initialization
2019-05-29 15:05:53,064 Training INFO: Model Articutures: VoxelNet(
  (_voxel_feature_extractor): VoxelFeatureExtractorV3()
  (_middle_feature_extractor): SpMiddleFHD(
    (middle_conv): SparseSequential(
      (0): DefaultArgLayer()
      (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): DefaultArgLayer()
      (4): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): DefaultArgLayer()
      (7): DefaultArgLayer(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (8): ReLU()
      (9): DefaultArgLayer()
      (10): DefaultArgLayer(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (11): ReLU()
      (12): DefaultArgLayer()
      (13): DefaultArgLayer(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (14): ReLU()
      (15): DefaultArgLayer()
      (16): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (17): ReLU()
      (18): DefaultArgLayer()
      (19): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (20): ReLU()
      (21): DefaultArgLayer()
      (22): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (23): ReLU()
      (24): DefaultArgLayer()
      (25): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (26): ReLU()
      (27): DefaultArgLayer()
      (28): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (29): ReLU()
      (30): DefaultArgLayer()
      (31): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (32): ReLU()
      (33): DefaultArgLayer()
      (34): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (35): ReLU()
      (36): DefaultArgLayer()
      (37): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (38): ReLU()
      (39): DefaultArgLayer()
      (40): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (41): ReLU()
    )
  )
  (_rpn): RPNV2(
    (blocks): ModuleList(
      (0): Sequential(
        (0): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
        (1): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
        (2): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (3): ReLU()
        (4): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (5): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (6): ReLU()
        (7): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (8): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (9): ReLU()
        (10): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (11): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (12): ReLU()
        (13): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (14): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (15): ReLU()
        (16): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (17): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (18): ReLU()
      )
      (1): Sequential(
        (0): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
        (1): DefaultArgLayer(128, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)
        (2): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (3): ReLU()
        (4): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (5): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (6): ReLU()
        (7): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (8): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (9): ReLU()
        (10): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (11): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (12): ReLU()
        (13): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (14): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (15): ReLU()
        (16): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (17): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (18): ReLU()
      )
    )
    (deblocks): ModuleList(
      (0): Sequential(
        (0): DefaultArgLayer(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (1): Sequential(
        (0): DefaultArgLayer(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
        (1): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
    (tasks): ModuleList(
      (0): RPNHead(
        (conv_box): Conv2d(384, 18, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 2, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 4, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): RPNHead(
        (conv_box): Conv2d(384, 36, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
      )
      (2): RPNHead(
        (conv_box): Conv2d(384, 36, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
      )
      (3): RPNHead(
        (conv_box): Conv2d(384, 18, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 2, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 4, kernel_size=(1, 1), stride=(1, 1))
      )
      (4): RPNHead(
        (conv_box): Conv2d(384, 36, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
      )
      (5): RPNHead(
        (conv_box): Conv2d(384, 36, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
  (rpn_acc): Accuracy()
  (rpn_precision): Precision()
  (rpn_recall): Recall()
  (rpn_metrics): PrecisionRecall()
  (rpn_cls_loss): Scalar()
  (rpn_loc_loss): Scalar()
  (rpn_total_loss): Scalar()
)
2019-05-29 15:06:03,166 Training INFO: Training use Single-GPU
2019-05-29 15:10:57,190 3d-object-detection INFO: Using 1 GPUs
2019-05-29 15:10:57,190 3d-object-detection INFO: Namespace(cfg='configs/all_nuscene_fhd.yaml', distributed=False, local_rank=0, model_dir='nusc/')
2019-05-29 15:10:57,190 3d-object-detection INFO: Collecting env info (might take some time)
2019-05-29 15:11:02,757 3d-object-detection INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.6 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609
CMake version: version 3.13.4

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 1080 Ti
Nvidia driver version: 390.30
cuDNN version: /unsullied/sharefs/_admin/cuda/cuda-9.0/cudnn/v7.4.1/lib64/libcudnn.so.7.4.1

Versions of relevant libraries:
[pip3] numpy==1.14.5
[pip3] numpydoc==0.8.0
[pip3] torch==1.1.0
[pip3] torchvision==0.2.2.post3
[conda] blas                      1.0                         mkl  
[conda] mkl                       2018.0.2                      1  
[conda] mkl-service               1.1.2            py36h17a0993_4  
[conda] mkl_fft                   1.0.1            py36h3010b51_0  
[conda] mkl_random                1.0.1            py36h629b387_0  
[conda] torch                     1.1.0                    pypi_0    pypi
[conda] torchvision               0.2.2.post3              pypi_0    pypi
        Pillow (5.2.0)
2019-05-29 15:11:02,758 3d-object-detection INFO: 
local_rank: 0
input:
    num_point_features: 5
    voxel:
        voxel_size: [0.1, 0.1, 0.2]
        point_cloud_range: [-50.4, -50.4, -5.0, 50.4, 50.4, 3.0]
        max_num_points: 20
        max_num_voxels: 40000
    train:
        batch_size: 5
        num_epochs: 20
        dataset:
            type: "NuScenesDataset"
            root_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data"
            info_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data/infos_train_10sweeps_withvelo.pkl"
            nsweeps: 10
        preprocess:
            shuffle: False
            num_workers: 5
            gt_location_noise: [0, 0, 0]
            gt_rotation_noise: [0, 0]
            global_rotation_noise: [-0.3925, 0.3925]
            global_scale_noise: [0.95, 1.05]
            global_rotation_per_object_range: [0, 0]
            global_translation_noise: [0.2, 0.2, 0.2]
            anchor_area_threshold: -1
            remove_points_after_sample: False
            gt_drop_percentage: 0.0
            gt_drop_max_keep_points: 15
            remove_unknow_examples: False
            remove_environment: False
            db_sampler:
                enable: True
                db_info_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data/dbinfos_train_10sweeps_withvelo.pkl"
                db_preprocess_steps:
                    filter_by_min_num_points:
                        type: "filter_by_min_num_points"
                        classes: ["car","truck", "construction_vehicle", "bus", "trailer", "barrier", "motorcycle", "bicycle", "pedestrian", "traffic_cone"] 
                        values: [5, 5, 5, 5, 5, 5, 5, 5, 5, 5]
                    filter_by_difficulty:
                        type: "filter_by_difficulty"
                        value: [-1,]
                global_random_rotation_range_per_object: [0, 0]
                rate: 1.0
                sample_groups:
                     classes: ["car","truck", "construction_vehicle", "bus", "trailer", "barrier", "motorcycle", "bicycle", "pedestrian", "traffic_cone"] 
                     values: [2, 3, 7, 4, 6, 2, 6, 6, 2, 2]

    eval:
        batch_size: 5
        dataset:
            type: "NuScenesDataset"
            root_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data"
            info_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data/infos_val_10sweeps_withvelo.pkl"
            nsweeps: 10
        preprocess:
            max_num_voxels: 60000
            shuffle: False
            num_workers: 3
            anchor_area_threshold: -1
            remove_environment: False

box_coder:
    type: "ground_box3d_coder"
    value:
        n_dim: 9
        linear_dim: False
        encode_angle_vector: False

target_assigner:
    anchor_generators:
        anchor_types: ["anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range"]
        anchor_dims: [9,9,9,9,9,9,9,9,9,9]
        anchor_sizes: [[1.97, 4.63, 1.74],[2.51, 6.93, 2.84],[2.85, 6.37, 3.19],[2.94, 10.5, 3.47],[2.90, 12.29, 3.87],[2.53, 0.50, 0.98],[0.77, 2.11, 1.47],[0.60, 1.70, 1.28],[0.67, 0.73, 1.77],[0.41, 0.41, 1.07]]
        anchor_ranges: [[-50.4, -50.4, -0.95, 50.4, 50.4, -0.95],[-50.4, -50.4, -0.40, 50.4, 50.4, -0.40],[-50.4, -50.4, -0.225, 50.4, 50.4, -0.225],[-50.4, -50.4, -0.085, 50.4, 50.4, -0.085],[-50.4, -50.4, 0.115, 50.4, 50.4, 0.115],[-50.4, -50.4, -1.33, 50.4, 50.4, -1.33],[-50.4, -50.4, -1.085, 50.4, 50.4, -1.085],[-50.4, -50.4, -1.18, 50.4, 50.4, -1.18],[-50.4, -50.4, -0.935, 50.4, 50.4, -0.935],[-50.4, -50.4, -1.285, 50.4, 50.4, -1.285]]
        anchor_rotations: [[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57]]
        anchor_velocities: [[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0]]
        anchor_matched_thresholds: [0.6,0.55,0.5,0.55,0.5,0.55,0.5,0.5,0.6,0.6]
        anchor_unmatched_thresholds: [0.45,0.4,0.3,0.4,0.35,0.4,0.3,0.35,0.4,0.4]
        anchor_class_names: ["car","truck", "construction_vehicle", "bus", "trailer", "barrier", "motorcycle", "bicycle", "pedestrian", "traffic_cone"]
        sample_positive_fraction: -1
        sample_size: 512
        region_similarity_calculator: 
            type: "nearest_iou_similarity"
            value: 0
model:
    encoder:
        vfe:
            type: "VoxelFeatureExtractorV3" #"PIXORFeatureLayer"
            num_filters: [16,]
            with_distance: False
            num_input_features: 5
        middle:
            type: "SpMiddleFHD"
            num_filters_down1: []
            num_filters_down2: []
            downsample_factor: 8
            num_input_features: 5
    decoder:
        rpn:
            type: "RPNV2"
            layer_nums: [5, 5]
            downsample_layer_strides: [1, 2]
            downsample_num_filters: [128, 256]
            upsample_layer_strides: [1, 2]
            upsample_num_filters: [128, 256]
            group_norm: False
            num_groups: 32
            num_input_features: 128
        head:
            tasks:
                num_classes: [1, 2, 2, 1, 2, 2]
                class_names: [["car"], ["truck", "construction_vehicle"], ["bus", "trailer"], ["barrier"], ["motorcycle", "bicycle"], ["pedestrian", "traffic_cone"]]
            weights: [0.7, 1.2, 1.5, 1.2, 1.5, 0.8]
        auxiliary:
            use_direction_classifier: True
            direction_offset: 0.785
    post_process:
        post_center_limit_range: [-61.2, -61.2, -10.0, 61.2, 61.2, 10.0]
        use_rotate_nms: True
        use_multi_class_nms: False
        nms_pre_max_size: 1000
        nms_post_max_size: 80
        nms_score_threshold: 0.1
        nms_iou_threshold: 0.2

    loss:
        loss_scale_factor: -1
        loss_norm_type: "NormByNumPositives"
        pos_class_weight: 1.0
        neg_class_weight: 2.0
        use_sigmoid_score: True
        encode_background_as_zeros: True
        encode_rad_error_by_sin: True
        classification_loss:
            type: "weighted_sigmoid_focal"
            value: 
                alpha: 0.25
                gamma: 2.0
                anchorwise_output: True
        localization_loss:
            type: "weighted_smooth_l1"
            value: 
                sigma: 3.0
                code_weight: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.2, 1.0]
        classification_loss_weight: 1.0
        localization_loss_weight: 1.0
        direction_loss_weight: 0.2
        rpn_thresholds: [0.1,0.3,0.5,0.7,0.8,0.9]

optimizer:
    type: "adam"
    value: 
        lr:
            type: "one_cycle"
            value: 
                lr_max: 0.04
                moms: [0.95, 0.85]
                div_factor: 10.0
                pct_start: 0.4
        amsgrad: 0.0
        wd: 0.01
    fixed_wd: True
    moving_average: False

2019-05-29 15:11:03,440 Training INFO: Using direction offset 0.785000 to fix aoe
2019-05-29 15:11:03,441 Training INFO: Voxel Feature Encoder: VoxelFeatureExtractorV3
2019-05-29 15:11:03,441 Training INFO: Middle class name: SpMiddleFHD
2019-05-29 15:11:03,457 Training INFO: RPN class name: RPNV2
2019-05-29 15:11:03,503 Training INFO: num_classes: [1, 2, 2, 1, 2, 2]
2019-05-29 15:11:03,503 Training INFO: num_preds: [18, 36, 36, 18, 36, 36]
2019-05-29 15:11:03,504 Training INFO: num_dirs: [4, 8, 8, 4, 8, 8]
2019-05-29 15:11:03,510 Training INFO: Finish RPNBase Initialization
2019-05-29 15:11:03,511 Training INFO: Model Articutures: VoxelNet(
  (_voxel_feature_extractor): VoxelFeatureExtractorV3()
  (_middle_feature_extractor): SpMiddleFHD(
    (middle_conv): SparseSequential(
      (0): DefaultArgLayer()
      (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): DefaultArgLayer()
      (4): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): DefaultArgLayer()
      (7): DefaultArgLayer(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (8): ReLU()
      (9): DefaultArgLayer()
      (10): DefaultArgLayer(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (11): ReLU()
      (12): DefaultArgLayer()
      (13): DefaultArgLayer(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (14): ReLU()
      (15): DefaultArgLayer()
      (16): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (17): ReLU()
      (18): DefaultArgLayer()
      (19): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (20): ReLU()
      (21): DefaultArgLayer()
      (22): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (23): ReLU()
      (24): DefaultArgLayer()
      (25): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (26): ReLU()
      (27): DefaultArgLayer()
      (28): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (29): ReLU()
      (30): DefaultArgLayer()
      (31): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (32): ReLU()
      (33): DefaultArgLayer()
      (34): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (35): ReLU()
      (36): DefaultArgLayer()
      (37): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (38): ReLU()
      (39): DefaultArgLayer()
      (40): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (41): ReLU()
    )
  )
  (_rpn): RPNV2(
    (blocks): ModuleList(
      (0): Sequential(
        (0): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
        (1): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
        (2): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (3): ReLU()
        (4): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (5): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (6): ReLU()
        (7): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (8): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (9): ReLU()
        (10): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (11): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (12): ReLU()
        (13): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (14): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (15): ReLU()
        (16): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (17): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (18): ReLU()
      )
      (1): Sequential(
        (0): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
        (1): DefaultArgLayer(128, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)
        (2): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (3): ReLU()
        (4): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (5): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (6): ReLU()
        (7): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (8): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (9): ReLU()
        (10): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (11): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (12): ReLU()
        (13): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (14): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (15): ReLU()
        (16): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (17): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (18): ReLU()
      )
    )
    (deblocks): ModuleList(
      (0): Sequential(
        (0): DefaultArgLayer(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (1): Sequential(
        (0): DefaultArgLayer(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
        (1): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
    (tasks): ModuleList(
      (0): RPNHead(
        (conv_box): Conv2d(384, 18, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 2, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 4, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): RPNHead(
        (conv_box): Conv2d(384, 36, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
      )
      (2): RPNHead(
        (conv_box): Conv2d(384, 36, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
      )
      (3): RPNHead(
        (conv_box): Conv2d(384, 18, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 2, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 4, kernel_size=(1, 1), stride=(1, 1))
      )
      (4): RPNHead(
        (conv_box): Conv2d(384, 36, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
      )
      (5): RPNHead(
        (conv_box): Conv2d(384, 36, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
  (rpn_acc): Accuracy()
  (rpn_precision): Precision()
  (rpn_recall): Recall()
  (rpn_metrics): PrecisionRecall()
  (rpn_cls_loss): Scalar()
  (rpn_loc_loss): Scalar()
  (rpn_total_loss): Scalar()
)
2019-05-29 15:11:13,321 Training INFO: Training use Single-GPU
2019-05-29 15:11:13,323 Training INFO: No checkpoint found. Initializing model from scratch
2019-05-29 15:11:13,323 Training INFO: Finish start eval ...
2019-05-29 15:11:13,323 Training INFO: Start evaluation on dataset for 6019 samples.
2019-05-29 15:15:37,139 3d-object-detection INFO: Using 1 GPUs
2019-05-29 15:15:37,139 3d-object-detection INFO: Namespace(cfg='configs/all_nuscene_fhd.yaml', distributed=False, local_rank=0, model_dir='nusc/')
2019-05-29 15:15:37,140 3d-object-detection INFO: Collecting env info (might take some time)
2019-05-29 15:15:42,551 3d-object-detection INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.6 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609
CMake version: version 3.13.4

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 1080 Ti
Nvidia driver version: 390.30
cuDNN version: /unsullied/sharefs/_admin/cuda/cuda-9.0/cudnn/v7.4.1/lib64/libcudnn.so.7.4.1

Versions of relevant libraries:
[pip3] numpy==1.14.5
[pip3] numpydoc==0.8.0
[pip3] torch==1.1.0
[pip3] torchvision==0.2.2.post3
[conda] blas                      1.0                         mkl  
[conda] mkl                       2018.0.2                      1  
[conda] mkl-service               1.1.2            py36h17a0993_4  
[conda] mkl_fft                   1.0.1            py36h3010b51_0  
[conda] mkl_random                1.0.1            py36h629b387_0  
[conda] torch                     1.1.0                    pypi_0    pypi
[conda] torchvision               0.2.2.post3              pypi_0    pypi
        Pillow (5.2.0)
2019-05-29 15:15:42,551 3d-object-detection INFO: 
local_rank: 0
input:
    num_point_features: 5
    voxel:
        voxel_size: [0.1, 0.1, 0.2]
        point_cloud_range: [-50.4, -50.4, -5.0, 50.4, 50.4, 3.0]
        max_num_points: 20
        max_num_voxels: 40000
    train:
        batch_size: 5
        num_epochs: 20
        dataset:
            type: "NuScenesDataset"
            root_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data"
            info_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data/infos_train_10sweeps_withvelo.pkl"
            nsweeps: 10
        preprocess:
            shuffle: False
            num_workers: 5
            gt_location_noise: [0, 0, 0]
            gt_rotation_noise: [0, 0]
            global_rotation_noise: [-0.3925, 0.3925]
            global_scale_noise: [0.95, 1.05]
            global_rotation_per_object_range: [0, 0]
            global_translation_noise: [0.2, 0.2, 0.2]
            anchor_area_threshold: -1
            remove_points_after_sample: False
            gt_drop_percentage: 0.0
            gt_drop_max_keep_points: 15
            remove_unknow_examples: False
            remove_environment: False
            db_sampler:
                enable: True
                db_info_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data/dbinfos_train_10sweeps_withvelo.pkl"
                db_preprocess_steps:
                    filter_by_min_num_points:
                        type: "filter_by_min_num_points"
                        classes: ["car","truck", "construction_vehicle", "bus", "trailer", "barrier", "motorcycle", "bicycle", "pedestrian", "traffic_cone"] 
                        values: [5, 5, 5, 5, 5, 5, 5, 5, 5, 5]
                    filter_by_difficulty:
                        type: "filter_by_difficulty"
                        value: [-1,]
                global_random_rotation_range_per_object: [0, 0]
                rate: 1.0
                sample_groups:
                     classes: ["car","truck", "construction_vehicle", "bus", "trailer", "barrier", "motorcycle", "bicycle", "pedestrian", "traffic_cone"] 
                     values: [2, 3, 7, 4, 6, 2, 6, 6, 2, 2]

    eval:
        batch_size: 5
        dataset:
            type: "NuScenesDataset"
            root_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data"
            info_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data/infos_val_10sweeps_withvelo.pkl"
            nsweeps: 10
        preprocess:
            max_num_voxels: 60000
            shuffle: False
            num_workers: 3
            anchor_area_threshold: -1
            remove_environment: False

box_coder:
    type: "ground_box3d_coder"
    value:
        n_dim: 9
        linear_dim: False
        encode_angle_vector: False

target_assigner:
    anchor_generators:
        anchor_types: ["anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range"]
        anchor_dims: [9,9,9,9,9,9,9,9,9,9]
        anchor_sizes: [[1.97, 4.63, 1.74],[2.51, 6.93, 2.84],[2.85, 6.37, 3.19],[2.94, 10.5, 3.47],[2.90, 12.29, 3.87],[2.53, 0.50, 0.98],[0.77, 2.11, 1.47],[0.60, 1.70, 1.28],[0.67, 0.73, 1.77],[0.41, 0.41, 1.07]]
        anchor_ranges: [[-50.4, -50.4, -0.95, 50.4, 50.4, -0.95],[-50.4, -50.4, -0.40, 50.4, 50.4, -0.40],[-50.4, -50.4, -0.225, 50.4, 50.4, -0.225],[-50.4, -50.4, -0.085, 50.4, 50.4, -0.085],[-50.4, -50.4, 0.115, 50.4, 50.4, 0.115],[-50.4, -50.4, -1.33, 50.4, 50.4, -1.33],[-50.4, -50.4, -1.085, 50.4, 50.4, -1.085],[-50.4, -50.4, -1.18, 50.4, 50.4, -1.18],[-50.4, -50.4, -0.935, 50.4, 50.4, -0.935],[-50.4, -50.4, -1.285, 50.4, 50.4, -1.285]]
        anchor_rotations: [[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57]]
        anchor_velocities: [[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0]]
        anchor_matched_thresholds: [0.6,0.55,0.5,0.55,0.5,0.55,0.5,0.5,0.6,0.6]
        anchor_unmatched_thresholds: [0.45,0.4,0.3,0.4,0.35,0.4,0.3,0.35,0.4,0.4]
        anchor_class_names: ["car","truck", "construction_vehicle", "bus", "trailer", "barrier", "motorcycle", "bicycle", "pedestrian", "traffic_cone"]
        sample_positive_fraction: -1
        sample_size: 512
        region_similarity_calculator: 
            type: "nearest_iou_similarity"
            value: 0
model:
    encoder:
        vfe:
            type: "VoxelFeatureExtractorV3" #"PIXORFeatureLayer"
            num_filters: [16,]
            with_distance: False
            num_input_features: 5
        middle:
            type: "SpMiddleFHD"
            num_filters_down1: []
            num_filters_down2: []
            downsample_factor: 8
            num_input_features: 5
    decoder:
        rpn:
            type: "RPNV2"
            layer_nums: [5, 5]
            downsample_layer_strides: [1, 2]
            downsample_num_filters: [128, 256]
            upsample_layer_strides: [1, 2]
            upsample_num_filters: [128, 256]
            group_norm: False
            num_groups: 32
            num_input_features: 128
        head:
            tasks:
                num_classes: [1, 2, 2, 1, 2, 2]
                class_names: [["car"], ["truck", "construction_vehicle"], ["bus", "trailer"], ["barrier"], ["motorcycle", "bicycle"], ["pedestrian", "traffic_cone"]]
            weights: [0.7, 1.2, 1.5, 1.2, 1.5, 0.8]
        auxiliary:
            use_direction_classifier: True
            direction_offset: 0.785
    post_process:
        post_center_limit_range: [-61.2, -61.2, -10.0, 61.2, 61.2, 10.0]
        use_rotate_nms: True
        use_multi_class_nms: False
        nms_pre_max_size: 1000
        nms_post_max_size: 80
        nms_score_threshold: 0.1
        nms_iou_threshold: 0.2

    loss:
        loss_scale_factor: -1
        loss_norm_type: "NormByNumPositives"
        pos_class_weight: 1.0
        neg_class_weight: 2.0
        use_sigmoid_score: True
        encode_background_as_zeros: True
        encode_rad_error_by_sin: True
        classification_loss:
            type: "weighted_sigmoid_focal"
            value: 
                alpha: 0.25
                gamma: 2.0
                anchorwise_output: True
        localization_loss:
            type: "weighted_smooth_l1"
            value: 
                sigma: 3.0
                code_weight: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.2, 1.0]
        classification_loss_weight: 1.0
        localization_loss_weight: 1.0
        direction_loss_weight: 0.2
        rpn_thresholds: [0.1,0.3,0.5,0.7,0.8,0.9]

optimizer:
    type: "adam"
    value: 
        lr:
            type: "one_cycle"
            value: 
                lr_max: 0.04
                moms: [0.95, 0.85]
                div_factor: 10.0
                pct_start: 0.4
        amsgrad: 0.0
        wd: 0.01
    fixed_wd: True
    moving_average: False

2019-05-29 15:15:43,239 Training INFO: Using direction offset 0.785000 to fix aoe
2019-05-29 15:15:43,239 Training INFO: Voxel Feature Encoder: VoxelFeatureExtractorV3
2019-05-29 15:15:43,240 Training INFO: Middle class name: SpMiddleFHD
2019-05-29 15:15:43,255 Training INFO: RPN class name: RPNV2
2019-05-29 15:15:43,299 Training INFO: num_classes: [1, 2, 2, 1, 2, 2]
2019-05-29 15:15:43,300 Training INFO: num_preds: [18, 36, 36, 18, 36, 36]
2019-05-29 15:15:43,300 Training INFO: num_dirs: [4, 8, 8, 4, 8, 8]
2019-05-29 15:15:43,304 Training INFO: Finish RPNBase Initialization
2019-05-29 15:15:43,305 Training INFO: Model Articutures: VoxelNet(
  (_voxel_feature_extractor): VoxelFeatureExtractorV3()
  (_middle_feature_extractor): SpMiddleFHD(
    (middle_conv): SparseSequential(
      (0): DefaultArgLayer()
      (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): DefaultArgLayer()
      (4): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): DefaultArgLayer()
      (7): DefaultArgLayer(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (8): ReLU()
      (9): DefaultArgLayer()
      (10): DefaultArgLayer(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (11): ReLU()
      (12): DefaultArgLayer()
      (13): DefaultArgLayer(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (14): ReLU()
      (15): DefaultArgLayer()
      (16): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (17): ReLU()
      (18): DefaultArgLayer()
      (19): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (20): ReLU()
      (21): DefaultArgLayer()
      (22): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (23): ReLU()
      (24): DefaultArgLayer()
      (25): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (26): ReLU()
      (27): DefaultArgLayer()
      (28): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (29): ReLU()
      (30): DefaultArgLayer()
      (31): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (32): ReLU()
      (33): DefaultArgLayer()
      (34): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (35): ReLU()
      (36): DefaultArgLayer()
      (37): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (38): ReLU()
      (39): DefaultArgLayer()
      (40): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (41): ReLU()
    )
  )
  (_rpn): RPNV2(
    (blocks): ModuleList(
      (0): Sequential(
        (0): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
        (1): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
        (2): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (3): ReLU()
        (4): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (5): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (6): ReLU()
        (7): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (8): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (9): ReLU()
        (10): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (11): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (12): ReLU()
        (13): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (14): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (15): ReLU()
        (16): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (17): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (18): ReLU()
      )
      (1): Sequential(
        (0): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
        (1): DefaultArgLayer(128, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)
        (2): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (3): ReLU()
        (4): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (5): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (6): ReLU()
        (7): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (8): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (9): ReLU()
        (10): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (11): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (12): ReLU()
        (13): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (14): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (15): ReLU()
        (16): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (17): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (18): ReLU()
      )
    )
    (deblocks): ModuleList(
      (0): Sequential(
        (0): DefaultArgLayer(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (1): Sequential(
        (0): DefaultArgLayer(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
        (1): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
    (tasks): ModuleList(
      (0): RPNHead(
        (conv_box): Conv2d(384, 18, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 2, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 4, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): RPNHead(
        (conv_box): Conv2d(384, 36, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
      )
      (2): RPNHead(
        (conv_box): Conv2d(384, 36, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
      )
      (3): RPNHead(
        (conv_box): Conv2d(384, 18, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 2, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 4, kernel_size=(1, 1), stride=(1, 1))
      )
      (4): RPNHead(
        (conv_box): Conv2d(384, 36, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
      )
      (5): RPNHead(
        (conv_box): Conv2d(384, 36, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
  (rpn_acc): Accuracy()
  (rpn_precision): Precision()
  (rpn_recall): Recall()
  (rpn_metrics): PrecisionRecall()
  (rpn_cls_loss): Scalar()
  (rpn_loc_loss): Scalar()
  (rpn_total_loss): Scalar()
)
2019-05-29 15:15:52,970 Training INFO: Training use Single-GPU
2019-05-29 15:15:52,972 Training INFO: Loading checkpoint from ./last_checkpoint.pth
2019-05-29 15:16:41,117 3d-object-detection INFO: Using 1 GPUs
2019-05-29 15:16:41,117 3d-object-detection INFO: Namespace(cfg='configs/all_nuscene_fhd.yaml', distributed=False, local_rank=0, model_dir='nusc/')
2019-05-29 15:16:41,117 3d-object-detection INFO: Collecting env info (might take some time)
2019-05-29 15:16:46,120 3d-object-detection INFO: 
PyTorch version: 1.1.0
Is debug build: No
CUDA used to build PyTorch: 9.0.176

OS: Ubuntu 16.04.6 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609
CMake version: version 3.13.4

Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 9.0.176
GPU models and configuration: GPU 0: GeForce GTX 1080 Ti
Nvidia driver version: 390.30
cuDNN version: /unsullied/sharefs/_admin/cuda/cuda-9.0/cudnn/v7.4.1/lib64/libcudnn.so.7.4.1

Versions of relevant libraries:
[pip3] numpy==1.14.5
[pip3] numpydoc==0.8.0
[pip3] torch==1.1.0
[pip3] torchvision==0.2.2.post3
[conda] blas                      1.0                         mkl  
[conda] mkl                       2018.0.2                      1  
[conda] mkl-service               1.1.2            py36h17a0993_4  
[conda] mkl_fft                   1.0.1            py36h3010b51_0  
[conda] mkl_random                1.0.1            py36h629b387_0  
[conda] torch                     1.1.0                    pypi_0    pypi
[conda] torchvision               0.2.2.post3              pypi_0    pypi
        Pillow (5.2.0)
2019-05-29 15:16:46,121 3d-object-detection INFO: 
local_rank: 0
input:
    num_point_features: 5
    voxel:
        voxel_size: [0.1, 0.1, 0.2]
        point_cloud_range: [-50.4, -50.4, -5.0, 50.4, 50.4, 3.0]
        max_num_points: 20
        max_num_voxels: 40000
    train:
        batch_size: 5
        num_epochs: 20
        dataset:
            type: "NuScenesDataset"
            root_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data"
            info_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data/infos_train_10sweeps_withvelo.pkl"
            nsweeps: 10
        preprocess:
            shuffle: False
            num_workers: 5
            gt_location_noise: [0, 0, 0]
            gt_rotation_noise: [0, 0]
            global_rotation_noise: [-0.3925, 0.3925]
            global_scale_noise: [0.95, 1.05]
            global_rotation_per_object_range: [0, 0]
            global_translation_noise: [0.2, 0.2, 0.2]
            anchor_area_threshold: -1
            remove_points_after_sample: False
            gt_drop_percentage: 0.0
            gt_drop_max_keep_points: 15
            remove_unknow_examples: False
            remove_environment: False
            db_sampler:
                enable: True
                db_info_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data/dbinfos_train_10sweeps_withvelo.pkl"
                db_preprocess_steps:
                    filter_by_min_num_points:
                        type: "filter_by_min_num_points"
                        classes: ["car","truck", "construction_vehicle", "bus", "trailer", "barrier", "motorcycle", "bicycle", "pedestrian", "traffic_cone"] 
                        values: [5, 5, 5, 5, 5, 5, 5, 5, 5, 5]
                    filter_by_difficulty:
                        type: "filter_by_difficulty"
                        value: [-1,]
                global_random_rotation_range_per_object: [0, 0]
                rate: 1.0
                sample_groups:
                     classes: ["car","truck", "construction_vehicle", "bus", "trailer", "barrier", "motorcycle", "bicycle", "pedestrian", "traffic_cone"] 
                     values: [2, 3, 7, 4, 6, 2, 6, 6, 2, 2]

    eval:
        batch_size: 5
        dataset:
            type: "NuScenesDataset"
            root_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data"
            info_path: "/unsullied/sharefs/_research_detection/GeneralDetection/NuScenes/full_data/infos_val_10sweeps_withvelo.pkl"
            nsweeps: 10
        preprocess:
            max_num_voxels: 60000
            shuffle: False
            num_workers: 3
            anchor_area_threshold: -1
            remove_environment: False

box_coder:
    type: "ground_box3d_coder"
    value:
        n_dim: 9
        linear_dim: False
        encode_angle_vector: False

target_assigner:
    anchor_generators:
        anchor_types: ["anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range","anchor_generator_range"]
        anchor_dims: [9,9,9,9,9,9,9,9,9,9]
        anchor_sizes: [[1.97, 4.63, 1.74],[2.51, 6.93, 2.84],[2.85, 6.37, 3.19],[2.94, 10.5, 3.47],[2.90, 12.29, 3.87],[2.53, 0.50, 0.98],[0.77, 2.11, 1.47],[0.60, 1.70, 1.28],[0.67, 0.73, 1.77],[0.41, 0.41, 1.07]]
        anchor_ranges: [[-50.4, -50.4, -0.95, 50.4, 50.4, -0.95],[-50.4, -50.4, -0.40, 50.4, 50.4, -0.40],[-50.4, -50.4, -0.225, 50.4, 50.4, -0.225],[-50.4, -50.4, -0.085, 50.4, 50.4, -0.085],[-50.4, -50.4, 0.115, 50.4, 50.4, 0.115],[-50.4, -50.4, -1.33, 50.4, 50.4, -1.33],[-50.4, -50.4, -1.085, 50.4, 50.4, -1.085],[-50.4, -50.4, -1.18, 50.4, 50.4, -1.18],[-50.4, -50.4, -0.935, 50.4, 50.4, -0.935],[-50.4, -50.4, -1.285, 50.4, 50.4, -1.285]]
        anchor_rotations: [[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57],[0, 1.57]]
        anchor_velocities: [[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0]]
        anchor_matched_thresholds: [0.6,0.55,0.5,0.55,0.5,0.55,0.5,0.5,0.6,0.6]
        anchor_unmatched_thresholds: [0.45,0.4,0.3,0.4,0.35,0.4,0.3,0.35,0.4,0.4]
        anchor_class_names: ["car","truck", "construction_vehicle", "bus", "trailer", "barrier", "motorcycle", "bicycle", "pedestrian", "traffic_cone"]
        sample_positive_fraction: -1
        sample_size: 512
        region_similarity_calculator: 
            type: "nearest_iou_similarity"
            value: 0
model:
    encoder:
        vfe:
            type: "VoxelFeatureExtractorV3" #"PIXORFeatureLayer"
            num_filters: [16,]
            with_distance: False
            num_input_features: 5
        middle:
            type: "SpMiddleFHD"
            num_filters_down1: []
            num_filters_down2: []
            downsample_factor: 8
            num_input_features: 5
    decoder:
        rpn:
            type: "RPNV2"
            layer_nums: [5, 5]
            downsample_layer_strides: [1, 2]
            downsample_num_filters: [128, 256]
            upsample_layer_strides: [1, 2]
            upsample_num_filters: [128, 256]
            group_norm: False
            num_groups: 32
            num_input_features: 128
        head:
            tasks:
                num_classes: [1, 2, 2, 1, 2, 2]
                class_names: [["car"], ["truck", "construction_vehicle"], ["bus", "trailer"], ["barrier"], ["motorcycle", "bicycle"], ["pedestrian", "traffic_cone"]]
            weights: [0.7, 1.2, 1.5, 1.2, 1.5, 0.8]
        auxiliary:
            use_direction_classifier: True
            direction_offset: 0.785
    post_process:
        post_center_limit_range: [-61.2, -61.2, -10.0, 61.2, 61.2, 10.0]
        use_rotate_nms: True
        use_multi_class_nms: False
        nms_pre_max_size: 1000
        nms_post_max_size: 80
        nms_score_threshold: 0.1
        nms_iou_threshold: 0.2

    loss:
        loss_scale_factor: -1
        loss_norm_type: "NormByNumPositives"
        pos_class_weight: 1.0
        neg_class_weight: 2.0
        use_sigmoid_score: True
        encode_background_as_zeros: True
        encode_rad_error_by_sin: True
        classification_loss:
            type: "weighted_sigmoid_focal"
            value: 
                alpha: 0.25
                gamma: 2.0
                anchorwise_output: True
        localization_loss:
            type: "weighted_smooth_l1"
            value: 
                sigma: 3.0
                code_weight: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.2, 1.0]
        classification_loss_weight: 1.0
        localization_loss_weight: 1.0
        direction_loss_weight: 0.2
        rpn_thresholds: [0.1,0.3,0.5,0.7,0.8,0.9]

optimizer:
    type: "adam"
    value: 
        lr:
            type: "one_cycle"
            value: 
                lr_max: 0.04
                moms: [0.95, 0.85]
                div_factor: 10.0
                pct_start: 0.4
        amsgrad: 0.0
        wd: 0.01
    fixed_wd: True
    moving_average: False

2019-05-29 15:16:46,829 Training INFO: Using direction offset 0.785000 to fix aoe
2019-05-29 15:16:46,829 Training INFO: Voxel Feature Encoder: VoxelFeatureExtractorV3
2019-05-29 15:16:46,830 Training INFO: Middle class name: SpMiddleFHD
2019-05-29 15:16:46,847 Training INFO: RPN class name: RPNV2
2019-05-29 15:16:46,893 Training INFO: num_classes: [1, 2, 2, 1, 2, 2]
2019-05-29 15:16:46,893 Training INFO: num_preds: [18, 36, 36, 18, 36, 36]
2019-05-29 15:16:46,893 Training INFO: num_dirs: [4, 8, 8, 4, 8, 8]
2019-05-29 15:16:46,899 Training INFO: Finish RPNBase Initialization
2019-05-29 15:16:46,901 Training INFO: Model Articutures: VoxelNet(
  (_voxel_feature_extractor): VoxelFeatureExtractorV3()
  (_middle_feature_extractor): SpMiddleFHD(
    (middle_conv): SparseSequential(
      (0): DefaultArgLayer()
      (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): DefaultArgLayer()
      (4): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU()
      (6): DefaultArgLayer()
      (7): DefaultArgLayer(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (8): ReLU()
      (9): DefaultArgLayer()
      (10): DefaultArgLayer(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (11): ReLU()
      (12): DefaultArgLayer()
      (13): DefaultArgLayer(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (14): ReLU()
      (15): DefaultArgLayer()
      (16): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (17): ReLU()
      (18): DefaultArgLayer()
      (19): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (20): ReLU()
      (21): DefaultArgLayer()
      (22): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (23): ReLU()
      (24): DefaultArgLayer()
      (25): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (26): ReLU()
      (27): DefaultArgLayer()
      (28): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (29): ReLU()
      (30): DefaultArgLayer()
      (31): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (32): ReLU()
      (33): DefaultArgLayer()
      (34): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (35): ReLU()
      (36): DefaultArgLayer()
      (37): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (38): ReLU()
      (39): DefaultArgLayer()
      (40): DefaultArgLayer(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (41): ReLU()
    )
  )
  (_rpn): RPNV2(
    (blocks): ModuleList(
      (0): Sequential(
        (0): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
        (1): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
        (2): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (3): ReLU()
        (4): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (5): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (6): ReLU()
        (7): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (8): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (9): ReLU()
        (10): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (11): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (12): ReLU()
        (13): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (14): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (15): ReLU()
        (16): DefaultArgLayer(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (17): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (18): ReLU()
      )
      (1): Sequential(
        (0): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
        (1): DefaultArgLayer(128, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)
        (2): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (3): ReLU()
        (4): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (5): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (6): ReLU()
        (7): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (8): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (9): ReLU()
        (10): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (11): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (12): ReLU()
        (13): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (14): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (15): ReLU()
        (16): DefaultArgLayer(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (17): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (18): ReLU()
      )
    )
    (deblocks): ModuleList(
      (0): Sequential(
        (0): DefaultArgLayer(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): DefaultArgLayer(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (1): Sequential(
        (0): DefaultArgLayer(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
        (1): DefaultArgLayer(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        (2): ReLU()
      )
    )
    (tasks): ModuleList(
      (0): RPNHead(
        (conv_box): Conv2d(384, 18, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 2, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 4, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): RPNHead(
        (conv_box): Conv2d(384, 36, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
      )
      (2): RPNHead(
        (conv_box): Conv2d(384, 36, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
      )
      (3): RPNHead(
        (conv_box): Conv2d(384, 18, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 2, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 4, kernel_size=(1, 1), stride=(1, 1))
      )
      (4): RPNHead(
        (conv_box): Conv2d(384, 36, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
      )
      (5): RPNHead(
        (conv_box): Conv2d(384, 36, kernel_size=(1, 1), stride=(1, 1))
        (conv_cls): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
        (conv_dir): Conv2d(384, 8, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
  (rpn_acc): Accuracy()
  (rpn_precision): Precision()
  (rpn_recall): Recall()
  (rpn_metrics): PrecisionRecall()
  (rpn_cls_loss): Scalar()
  (rpn_loc_loss): Scalar()
  (rpn_total_loss): Scalar()
)
2019-05-29 15:16:56,537 Training INFO: Training use Single-GPU
2019-05-29 15:16:56,540 Training INFO: Loading checkpoint from .nusc/last_checkpoint.pth
